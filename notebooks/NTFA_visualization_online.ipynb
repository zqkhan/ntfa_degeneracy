{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a35d49",
   "metadata": {},
   "source": [
    "# NTFA Visualization\n",
    "\n",
    "1. Spatial factor plot\n",
    "2. Embedding plots\n",
    "3. Voxel Noise\n",
    "4. Reconstruction\n",
    "5. Embedding distance and Activity distance RSA\n",
    "\n",
    "Yiyu 2022/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we're in our env (*)\n",
    "%conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fefca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for the NTFA package\n",
    "NTFA_path = \"/work/abslab/NTFA_packages/NTFADegeneracy/\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(NTFA_path)\n",
    "import htfa_torch.dtfa as DTFA\n",
    "import htfa_torch.niidb as niidb\n",
    "import htfa_torch.utils as utils\n",
    "import htfa_torch.tardb as tardb\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import webdataset as wds\n",
    "import torch\n",
    "import itertools\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from nilearn import plotting, image\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "from datetime import datetime\n",
    "datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('pdf', 'svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa321f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_dir = '/work/abslab/AVFP/denoised/'\n",
    "logfiles_dir = '/work/abslab/AVFP/logfiles/AffVidsNovel_logfiles/'\n",
    "\n",
    "mask_dir = '/home/wang.yiyu/AVFP/masks/'\n",
    "base_dir = '/work/abslab/Yiyu/NTFA_AVFP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860dddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** parameters that define the model directory ******\n",
    "subs = 20 #'All' #note, database file must have been created already for these subjects\n",
    "\n",
    "\n",
    "included_data = pd.read_csv(base_dir + 'fmri_info/included_avfp_subjects.csv', header=None)\n",
    "subIDs = included_data[0].astype('str').tolist()\n",
    "print(subIDs)\n",
    "total_subs = len(subIDs)\n",
    "print(f\"total subs = {total_subs}\")\n",
    "\n",
    "# using GM (and SNR) or SNR only?\n",
    "mask_type = 'GM' #'GMandSNR' #'SNR' or 'GM'\n",
    "\n",
    "# penalty weights (participant, stimulus, combination)\n",
    "p_weight, s_weight, c_weight = 1, 1, 1\n",
    "linear_opts = 'None' # 'C', 'PSC' 'None'\n",
    "# additional parameters:\n",
    "n_epoch = 1000\n",
    "n_factor = 100\n",
    "n_check = 50 # save checkpoints every n_check epochs for model\n",
    "\n",
    "\n",
    "\n",
    "# condition:\n",
    "condition = '_HeightsOnly'\n",
    "\n",
    "\n",
    "# noise model:\n",
    "noise_model = True\n",
    "voxel_noise = 0.3\n",
    "noise_opts = f'learned-{voxel_noise}' \n",
    "\n",
    "# noise_opts = f'fixed-{voxel_noise}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ff2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define database filename\n",
    "if subs != 'All':\n",
    "    #AVFP_FILE = 'data/AVFP_NTFA_memory_N' + str(n_files) + '_subsetN' + str(subs) + '_' + mask_type + 'mask.tar'\n",
    "    AVFP_FILE = base_dir + f'data/downsampled_test/AVFP_NTFA_N{total_subs}_subsetN{subs}_{mask_type}mask{condition}.tar'\n",
    "else: #including all subjects\n",
    "    AVFP_FILE = base_dir + f'data/AVFP_NTFA_N{total_subs}_{subs}_{mask_type}mask{condition}.tar'\n",
    "print('\\nFetching database:',AVFP_FILE)\n",
    "\n",
    "avfp_db = tardb.FmriTarDataset(AVFP_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directory and filename for saving model\n",
    "\n",
    "if noise_model:\n",
    "    query_dir = f'models/ablation_comparison/AVFP_NTFA_sub-{subs}_epoch-{n_epoch}_factor-{n_factor}_mask-{mask_type}_{p_weight}{s_weight}{c_weight}_lin-{linear_opts}_noise-{noise_opts}/'\n",
    "else:\n",
    "    query_dir = f'models/ablation_comparison/AVFP_NTFA_sub-{subs}_epoch-{n_epoch}_factor-{n_factor}_mask-{mask_type}_{p_weight}{s_weight}{c_weight}_lin-{linear_opts}/'\n",
    "\n",
    "if not os.path.isdir(query_dir):\n",
    "    os.makedirs(query_dir)\n",
    "print(\"\\nFetching model from: \", query_dir,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtfa = DTFA.DeepTFA(avfp_db, num_factors=n_factor, linear_params=linear_opts, query_name=query_dir, voxel_noise = 0.7652)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the initialized - kmeans - spatial factors (from dtfa.visualize_factor_embedding)\n",
    "\n",
    "fig = plt.figure(figsize=(7,3))\n",
    "results = dtfa.results()\n",
    "centers = results['factor_centers']\n",
    "widths = torch.exp(results['factor_log_widths'])\n",
    "plot = plotting.plot_connectome(\n",
    "    np.eye(dtfa.num_factors),\n",
    "    node_coords = centers.view(dtfa.num_factors, 3).numpy(),\n",
    "    node_size = widths.view(dtfa.num_factors).numpy(),\n",
    "    figure=fig\n",
    ")\n",
    "plt.suptitle('Spatial Factors: Initialized', size=20)\n",
    "#plt.savefig(query_dir + 'factors_initialized.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c570c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mask:\n",
    "mask = image.load_img(mask_dir + 'gm_mask_icbm152_brain.nii.gz')\n",
    "mask_data = mask.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6950797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_factor_locations():\n",
    "    count = 0\n",
    "    centers_np = centers.view(dtfa.num_factors, 3).numpy()\n",
    "    for i in range(centers_np.shape[0]):\n",
    "        coords = centers_np[i,:]\n",
    "        # apply inverse affine to go from world to voxel coordinates:\n",
    "        voxel_coords = np.round(image.coord_transform(coords[0], coords[1], coords[2], \n",
    "                                             np.linalg.inv(mask.affine))\n",
    "                               ).astype(int)\n",
    "        center_value = mask_data[voxel_coords[0], voxel_coords[1], voxel_coords[2]]\n",
    "        if center_value == 0: #if not in mask\n",
    "            count +=1\n",
    "            print('Factor center:',coords,voxel_coords)   \n",
    "    if count == 0:\n",
    "        print('\\nAll spatial factors are within the mask\\n')\n",
    "    else:\n",
    "        print('\\n',count,'factors are outside of the mask\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the most recent model (prefix for .dtfa_model and .dtfa_guide)\n",
    "checkpoint_files = glob.glob(query_dir + 'CHECK*dtfa*')\n",
    "state_name = max(checkpoint_files, key=os.path.getctime).split('.dtfa')[0]\n",
    "print('\\nLoading most recent checkpoint:',state_name,'\\n')\n",
    "\n",
    "dtfa.load_state(state_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3dac89-5582-4cfc-ae9c-89a3ce3a029a",
   "metadata": {},
   "source": [
    "# Spatial Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learned spatial factors - this will vary by subject\n",
    "block_plot = 0\n",
    "\n",
    "fig = plt.figure(figsize=(7,3))\n",
    "results = dtfa.results(block=block_plot)\n",
    "centers = results['factor_centers']\n",
    "widths = torch.exp(results['factor_log_widths'])\n",
    "plot = plotting.plot_connectome(\n",
    "    np.eye(dtfa.num_factors),\n",
    "    node_coords = centers.view(dtfa.num_factors, 3).numpy(),\n",
    "    node_size = widths.view(dtfa.num_factors).numpy(),\n",
    "    figure=fig\n",
    ")\n",
    "plt.suptitle('Spatial Factors (Block: ' + str(block_plot) + ')', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb42140",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparams = dtfa.variational.hyperparams.state_vardict()\n",
    "tasks = dtfa.tasks()\n",
    "subjects = dtfa.subjects()\n",
    "z_p_mu = hyperparams['subject_weight']['mu'].data\n",
    "z_s_mu = hyperparams['task']['mu'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b93cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ps_mu, combinations = list(), list()\n",
    "for p in range(len(subjects)):\n",
    "    # find index:\n",
    "    sub_tasks = [b['task'] for b in avfp_db.blocks.values() if b['subject'] == subjects[p]]\n",
    "    combinations.append(np.vstack([np.repeat(subjects[p],len(sub_tasks)), np.array(sub_tasks)]))\n",
    "    for t in range(len(sub_tasks)):\n",
    "        task_index = [i for i, e in enumerate(tasks) if e == sub_tasks[t]]\n",
    "        joint_embed = torch.cat((z_p_mu[p], z_s_mu[task_index[0]]), dim=-1)\n",
    "        interaction_embed = dtfa.decoder.interaction_embedding(joint_embed).data\n",
    "        z_ps_mu.append(interaction_embed.data.numpy())\n",
    "z_ps_mu = np.vstack(z_ps_mu)   \n",
    "combinations = np.hstack(combinations).T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_embeddings(): \n",
    "    hyperparams = dtfa.variational.hyperparams.state_vardict()\n",
    "    tasks = dtfa.tasks()\n",
    "    subjects = dtfa.subjects()\n",
    "    z_p_mu = hyperparams['subject_weight']['mu'].data\n",
    "    z_s_mu = hyperparams['task']['mu'].data\n",
    "\n",
    "    z_ps_mu, combinations = list(), list()\n",
    "    for p in range(len(subjects)):\n",
    "        # because I coded by memory, participants only have 1/2 of the unqiue tasks each - find index:\n",
    "        sub_tasks = [b['task'] for b in avfp_db.blocks.values() if b['subject'] == subjects[p]]\n",
    "        combinations.append(np.vstack([np.repeat(subjects[p],len(sub_tasks)), np.array(sub_tasks)]))\n",
    "        for t in range(len(sub_tasks)):\n",
    "            task_index = [i for i, e in enumerate(tasks) if e == sub_tasks[t]]\n",
    "            joint_embed = torch.cat((z_p_mu[p], z_s_mu[task_index[0]]), dim=-1)\n",
    "            interaction_embed = dtfa.decoder.interaction_embedding(joint_embed).data\n",
    "            z_ps_mu.append(interaction_embed.data.numpy())\n",
    "    z_ps_mu = np.vstack(z_ps_mu)   \n",
    "    combinations = np.hstack(combinations).T  \n",
    "\n",
    "    # convert to dataframes\n",
    "    z_p = pd.DataFrame(np.hstack([np.reshape(subjects, (len(subjects),1)), z_p_mu.numpy()]),\n",
    "                       columns=['participant','x','y'])\n",
    "    z_s = pd.DataFrame(np.hstack([np.reshape(tasks, (len(tasks),1)), z_s_mu.numpy()]),\n",
    "                       columns=['stimulus','x','y'])\n",
    "    z_ps = pd.DataFrame(np.hstack([combinations, z_ps_mu]),\n",
    "                        columns=['participant','stimulus','x','y'])\n",
    "    return z_p, z_s, z_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae2c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_embedding, s_embedding, c_embedding = fetch_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_embedding.participant = p_embedding.participant.astype('int').astype('string')\n",
    "p_embedding[['x','y']] = p_embedding[['x','y']].astype('float')\n",
    "p_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c82440",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_embedding[['x','y']] = s_embedding[['x','y']].astype('float')\n",
    "s_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef691102",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_embedding.participant = c_embedding.participant.astype('int').astype('string')\n",
    "c_embedding[['x','y']] = c_embedding[['x','y']].astype('float')\n",
    "c_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca777836-43e9-46d7-94e3-40993b88926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save embedding coordinates in pickle:\n",
    "p_embedding.to_pickle(query_dir + 'p_embedding.pkl')\n",
    "s_embedding.to_pickle(query_dir + 's_embedding.pkl')\n",
    "c_embedding.to_pickle(query_dir + 'c_embedding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalizable function to plot embeddings and colour-code by a variable\n",
    "# this variable should have been added to the embedding df\n",
    "# N embedding x 2 coordinates\n",
    "def plot_embeddings(embeddings, hue_var, label_vars=[], marker=16):\n",
    "    if 'participant' in embeddings.columns:\n",
    "        hover_vars = ['participant',hue_var]\n",
    "    else: hover_vars = [hue_var]\n",
    "    hover_vars.extend(label_vars)\n",
    "    \n",
    "    if 'z' not in embeddings.columns:\n",
    "        fig = px.scatter(embeddings, x='x', y='y',\n",
    "                         hover_data=hover_vars,color=hue_var,color_discrete_sequence=px.colors.qualitative.Light24)\n",
    "        fig.update_layout(height=500, width=600,               \n",
    "                  xaxis=dict(linecolor='black',mirror=True,linewidth=2,\n",
    "                             tickfont=dict(size=16, color='black'),\n",
    "                             titlefont=dict(size=20)),\n",
    "                  yaxis=dict(linecolor='black',mirror=True,linewidth=2,\n",
    "                             tickfont=dict(size=16, color='black'),\n",
    "                             titlefont=dict(size=20))\n",
    "                 )\n",
    "    else:\n",
    "        fig = px.scatter_3d(embeddings, x='x', y='y', z='z',\n",
    "                         hover_data=hover_vars,color=hue_var)\n",
    "        fig.update_layout(height=500, width=700, \n",
    "          scene_aspectmode='cube',\n",
    "          scene = dict(\n",
    "              xaxis=dict(linecolor='black',mirror=True,linewidth=2,\n",
    "                         tickfont=dict(size=16, color='black'),\n",
    "                         titlefont=dict(size=20)),\n",
    "              yaxis=dict(linecolor='black',mirror=True,linewidth=2,\n",
    "                         tickfont=dict(size=16, color='black'),\n",
    "                         titlefont=dict(size=20)),\n",
    "              zaxis=dict(linecolor='black',mirror=True,linewidth=2,\n",
    "                         tickfont=dict(size=16, color='black'),\n",
    "                         titlefont=dict(size=20)),\n",
    "          ), margin=dict(l=0.1, r=0.1, b=0.1, t=0.1)\n",
    "         )\n",
    "    fig.update_traces(marker=dict(size=marker))\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ed8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_embeddings(p_embedding, 'participant', marker=24)\n",
    "#fig.write_html(query_dir + 'participant_embeddings.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "situations = ['Heights','Social','Spiders']\n",
    "s_embedding['situation'] = ''\n",
    "for i in list(s_embedding.index):\n",
    "    for s in situations:\n",
    "        if s in s_embedding.stimulus[i]:\n",
    "            s_embedding.loc[i,'situation']=s\n",
    "            \n",
    "fig = plot_embeddings(s_embedding, 'stimulus', label_vars=['stimulus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e206bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "situations = ['Heights','Social','Spiders']\n",
    "c_embedding['situation'] = ''\n",
    "for i in list(c_embedding.index):\n",
    "    for s in situations:\n",
    "        \n",
    "        if s in c_embedding.stimulus[i]:\n",
    "            c_embedding.loc[i,'situation']=s\n",
    "            \n",
    "fig = plot_embeddings(c_embedding, 'participant', label_vars=['stimulus'], marker=8)\n",
    "#fig.write_image(query_dir + 'combination_embeddings.jpeg', scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d8224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "situations = ['Heights','Social','Spiders']\n",
    "c_embedding['situation'] = ''\n",
    "for i in list(c_embedding.index):\n",
    "    for s in situations:\n",
    "        \n",
    "        if s in c_embedding.stimulus[i]:\n",
    "            c_embedding.loc[i,'situation']=s\n",
    "            \n",
    "fig = plot_embeddings(c_embedding, 'stimulus', label_vars=['stimulus'], marker=8)\n",
    "#fig.write_image(query_dir + 'combination_embeddings.jpeg', scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f81dc7",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = torch.utils.data.DataLoader(dtfa._dataset.data(selector=lambda block: True), batch_size=128, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_activations, tr_blocks = [], []\n",
    "for tr in tr_data:\n",
    "    tr_activations.append(tr['activations'].numpy())\n",
    "    tr_blocks.extend(list(tr['block'].numpy()))\n",
    "tr_activations = np.concatenate(tr_activations, axis=0)\n",
    "tr_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f6a62-0116-4779-b6a6-74fa878549b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch *all* reconstructions\n",
    "reconstructions = []\n",
    "for b in np.unique(tr_blocks):\n",
    "    results = dtfa.results(block=b, generative=True)\n",
    "    # note, results contains the embedding info and factor weights\n",
    "    voxel_values = (results['weights'] @ results['factors']).numpy()\n",
    "    reconstructions.append(voxel_values)\n",
    "reconstructions = np.concatenate(reconstructions, axis=0)\n",
    "reconstructions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions for plotting the original brain and reconstruction\n",
    "# (adapted from dtfa and utils functions)\n",
    "\n",
    "def fetch_block_index(subjects=None, task=None, measure=None, \n",
    "                      value=None, value_type='exact', value_direction='higher'):\n",
    "    # block IDs belonging subject(s) and task/split\n",
    "    # will also be grouped by cluster ID at some point...\n",
    "    # measure should be modeled as a trial-specific \"individual differences\" (fix that phrasing in db script at a later date...)\n",
    "    # and will be returned based on value and value_type ('exact' — find that value — or 'quantile')\n",
    "    \n",
    "    if subjects is not None:\n",
    "        blocks = [b for b in avfp_db.blocks.values() for s in subjects if b['subject'] == s]\n",
    "    else: blocks = [b for b in avfp_db.blocks.values()]\n",
    "    if task is not None:\n",
    "        blocks = [b for b in blocks for t in task if t in b['task']]\n",
    "    if measure is not None:\n",
    "        if value_type == 'exact':\n",
    "            blocks = [b for b in blocks if b['individual_differences'][measure] == value]\n",
    "        elif value_type == 'quantile': \n",
    "            #note - abs() here is specific to our fear ratings - might want to adjust later on\n",
    "            # also note that quantile is across all blocks selected, so may need to zscore first\n",
    "            measure_values = np.array([np.abs(b['individual_differences'][measure]) for b in blocks])\n",
    "            measure_split = np.quantile(measure_values[~np.isnan(measure_values)], value)\n",
    "            if value_direction == 'higher':\n",
    "                blocks = [b for b in blocks if b['individual_differences'][measure] > measure_split]\n",
    "            elif value_direction == 'lower':\n",
    "                blocks = [b for b in blocks if b['individual_differences'][measure] <= measure_split]\n",
    "        \n",
    "    return [b['id'] for b in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brain_image(blocks, method):\n",
    "    # blocks = ids of blocks to average\n",
    "    activations = []\n",
    "    block_index = [i for i, e in enumerate(tr_blocks) if e in blocks]        \n",
    "    for b in blocks:\n",
    "        if method == 'original':\n",
    "            block_index = [i for i, e in enumerate(tr_blocks) if e == b]\n",
    "            voxel_values = tr_activations[block_index,:]\n",
    "        elif method == 'reconstruction':\n",
    "            # note, results contains the embedding info and factor weights\n",
    "            results = dtfa.results(block=b, generative=True)\n",
    "            voxel_values = (results['weights'] @ results['factors']).numpy()\n",
    "        activations.append(voxel_values)\n",
    "    #mean across all TRs/blocks\n",
    "    activations = np.concatenate(activations, axis=0)\n",
    "    activations = np.mean(activations, axis=0, keepdims=True) \n",
    "\n",
    "    #to nifti image\n",
    "    brain_image = utils.cmu2nii(activations,\n",
    "                          dtfa.voxel_locations.numpy(),\n",
    "                          dtfa._dataset.blocks[b]['template'])\n",
    "    return brain_image, activations\n",
    "\n",
    "def plot_brain(blocks, method, ax, zbound=3):\n",
    "    # plot mean contrast image\n",
    "    brain_image, activations = create_brain_image(blocks, method)\n",
    "    plot = plotting.plot_glass_brain(brain_image, plot_abs=False, colorbar=True,\n",
    "                                     symmetric_cbar=True, vmax=zbound, axes=ax)\n",
    "    ax.set_title(method, fontsize=16)\n",
    "    return activations\n",
    "\n",
    "    \n",
    "def plot_activations(blocks, subjects=None,\n",
    "                     task=None, measure=None, value=None):\n",
    "    # plot mean original and reconstruction\n",
    "    plt.figure(figsize=(12,2.5))\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    orig = plot_brain(blocks, 'original', ax, zbound=1.5)\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    recon = plot_brain(blocks, 'reconstruction', ax, zbound=1.5)\n",
    "    \n",
    "    # correlate (adjusting for the correlation between the block and other reconstructions)\n",
    "    corr = np.round(np.corrcoef(orig[0,:],recon[0,:])[0,1],3)\n",
    "    other_index = [i for i, e in enumerate(tr_blocks) if e not in blocks]\n",
    "    other_values = np.mean(reconstructions[other_index,:], axis=0, keepdims=True)\n",
    "    mean_corr = np.round(np.corrcoef(orig[0,:],other_values[0,:])[0,1],3)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1)\n",
    "    title = str(subjects) + ' ' + str(task) + ' ' + str(measure) + ' ' + str(value) \n",
    "    title = title.replace(\"None\",\"\")\n",
    "    plt.suptitle(title + \"   r = \" + str(corr) + \" (mean r = \" + str(mean_corr) + \")\", fontsize=18, y=1.1)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c9172-244f-464c-b720-34fb15492223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference(blocks, absolute_difference=False):\n",
    "    activations = []\n",
    "    reconstructions = []\n",
    "    differences =[]\n",
    "    for b in blocks:\n",
    "        \n",
    "        block_index = [i for i, e in enumerate(tr_blocks) if e == b]\n",
    "        tr_values = tr_activations[block_index,:]\n",
    "        \n",
    "            # note, results contains the embedding info and factor weights\n",
    "        results = dtfa.results(block=b, generative=True)\n",
    "        recon_values = (results['weights'] @ results['factors']).numpy()\n",
    "        \n",
    "        activations.append(tr_values)\n",
    "        reconstructions.append(recon_values)\n",
    "        \n",
    "        if absolute_difference:\n",
    "            differences.append([abs(np.mean(tr_values, axis=0) - np.mean(recon_values, axis =0))])\n",
    "        else:\n",
    "            differences.append([np.mean(tr_values, axis=0) - np.mean(recon_values, axis =0)])\n",
    "    activations = np.concatenate(activations, axis=0)\n",
    "    #activations = np.mean(activations, axis=0, keepdims=True)\n",
    "    \n",
    "    reconstructions = np.concatenate(reconstructions, axis=0)\n",
    "    #reconstructions = np.mean(reconstructions, axis=0, keepdims=True)\n",
    "    \n",
    "    differences = np.concatenate(differences)\n",
    "    \n",
    "    brain_image = utils.cmu2nii(differences,\n",
    "                          dtfa.voxel_locations.numpy(),\n",
    "                          dtfa._dataset.blocks[b]['template'])\n",
    "    \n",
    "    return activations, reconstructions, differences, brain_image  \n",
    "        \n",
    "def plot_voxel_noise(blocks, subjects=None,task=None, plot_individual=False, plot_average=False,absolute_difference=False):\n",
    "    avg_list = []\n",
    "    \n",
    "    activations, reconstructions, differences, diff_img = calculate_difference(blocks, absolute_difference)\n",
    "    for i in range(len(blocks)):\n",
    "        slice_data= differences[i,:]\n",
    "        std = np.round(np.std(slice_data),3)\n",
    "        avg = np.round(np.mean(slice_data),3)\n",
    "        \n",
    "        \n",
    "        avg_list.append(avg)\n",
    "        \n",
    "        if plot_individual:\n",
    "            value = '[blocks- ' + str(blocks[i])+ ']'\n",
    "            _, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "            ax.hist(slice_data, alpha=.8, bins=128)\n",
    "            title = str(subjects) + ' ' + str(task) + ' '+ value + ' mean = '+ str(avg) + ' std = ' + str(std)\n",
    "            title = title.replace(\"None\",\"\")\n",
    "            ax.set_title(title)\n",
    "            ax.grid(\"on\")\n",
    "        \n",
    "    if plot_average:\n",
    "        _, ax1 = plt.subplots(1, 1, figsize=(5, 5))\n",
    "        ax1.hist(avg_list, alpha=.8, bins=128)\n",
    "        title = 'distribution of mean difference for each block' + ': mean (of mean) = '+ str(np.round(np.mean(avg_list),3)) + ' sem = ' + str(np.round(np.std(avg_list),3))\n",
    "        title = title.replace(\"None\",\"\")\n",
    "        ax1.set_title(title)\n",
    "        ax1.grid(\"on\")\n",
    "            \n",
    "    return avg_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ad124-532d-4792-878a-1bd6a689d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks_to_plot = fetch_block_index(task=['Heights'])\n",
    "# avg_list = plot_voxel_noise(blocks_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f3a09-a7be-4ed2-893f-41692450b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks_to_plot = fetch_block_index(task=['Heights'])\n",
    "# avg_list = plot_voxel_noise(blocks_to_plot,absolute_difference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdf861-3081-4f82-9771-7b9a5a6f2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_sub = 107\n",
    "# blocks_to_plot = fetch_block_index(subjects=[this_sub])\n",
    "# avg_list_107 = plot_voxel_noise(blocks_to_plot, absolute_difference=True,plot_individual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00994dd7-5863-4358-af88-7bee06d6fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks_to_plot = fetch_block_index(task=['New_Heights_12_AVFP'])\n",
    "# h12= plot_voxel_noise(blocks_to_plot, absolute_difference=True,plot_individual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6356c762-3728-42ae-b960-0930a8ca86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_sub = 103\n",
    "# blocks_to_plot = fetch_block_index(subjects=[this_sub])\n",
    "# sub_103_list = plot_voxel_noise(blocks_to_plot, absolute_difference=True,plot_individual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e5924-15f7-40cd-ae94-4baadd7b1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_data = True\n",
    "n_per_subj = 2\n",
    "\n",
    "if hold_out_data:\n",
    "    rng = np.random.default_rng(2022)\n",
    "    test_blocks = []\n",
    "    for p in avfp_db.subjects():\n",
    "        sub_tasks = [b['task'] for b in avfp_db.blocks.values() if b['subject'] == p]\n",
    "        idx = rng.choice(len(sub_tasks), n_per_subj, replace=False)\n",
    "        for i in idx:\n",
    "            test_blocks.extend([b['id'] for b in avfp_db.blocks.values() if (b['subject'] == p) & (b['task'] == sub_tasks[i])])\n",
    "    test_blocks = np.sort(test_blocks).tolist()\n",
    "    print('Using',len(test_blocks),'blocks for testing\\nIDs:',test_blocks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95418f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filter = avfp_db.inference_filter_blocks(training=True, exclude_blocks=test_blocks)\n",
    "training_blocks = [b for (b, block) in dtfa._dataset.blocks.items() if training_filter(block)]\n",
    "print(training_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_filter = avfp_db.inference_filter_blocks(training=False, exclude_blocks=test_blocks)\n",
    "testing_blocks = [b for (b, block) in dtfa._dataset.blocks.items() if validation_filter(block)]\n",
    "print(testing_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations(testing_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5691f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations(training_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations([training_blocks[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b99eb3-16e7-43ef-afcf-2c135402a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations([training_blocks[40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802e244-d895-483a-aead-180b7d26a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations([testing_blocks[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08c9f5-3b1c-450a-8bed-6f37faa8d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations([testing_blocks[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c675b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible options: subject list, task list, measure string, value float\n",
    "\n",
    "blocks_to_average = fetch_block_index(task=['Heights'])\n",
    "plot_activations(blocks_to_average, task=['Heights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e660b-ec14-46b5-996b-c2c05c7846d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_to_average = fetch_block_index(task=['New_Heights_11_AVFP'])\n",
    "plot_activations(blocks_to_average, task=['New_Heights_11_AVFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c457e2-4803-4e14-ba07-bccba9960df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_to_average = fetch_block_index(task=['New_Heights_10_AVFP'])\n",
    "plot_activations(blocks_to_average, task=['New_Heights_10_AVFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0c33d-75e0-4bb6-8891-a2387f9fce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_to_average = fetch_block_index(task=['New_Heights_12_AVFP'])\n",
    "plot_activations(blocks_to_average, task=['New_Heights_12_AVFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fd456-7cae-4822-a425-2d9be87d6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_to_average = fetch_block_index(task=['New_Heights_2_AVFP'])\n",
    "plot_activations(blocks_to_average, task=['New_Heights_2_AVFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185610a5-79e7-408b-a58c-f851089d0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_sub = 103\n",
    "blocks_to_average = fetch_block_index(subjects=[this_sub])\n",
    "plot_activations(blocks_to_average, subjects=[this_sub])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3437de-4672-4307-a3ba-343ba436db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "this_sub = 107\n",
    "blocks_to_average = fetch_block_index(subjects=[this_sub])\n",
    "plot_activations(blocks_to_average, subjects=[this_sub]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134914b0-de65-4105-bbc4-3dc241742242",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_sub = 111\n",
    "blocks_to_average = fetch_block_index(subjects=[this_sub])\n",
    "plot_activations(blocks_to_average, subjects=[this_sub]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f17a0d-ee99-422d-b5fe-d656cb7ca664",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_sub = 119\n",
    "blocks_to_average = fetch_block_index(subjects=[this_sub])\n",
    "plot_activations(blocks_to_average, subjects=[this_sub]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5c040-7b5d-4f16-bec2-f7d63e099454",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_sub = 118\n",
    "blocks_to_average = fetch_block_index(subjects=[this_sub])\n",
    "plot_activations(blocks_to_average, subjects=[this_sub]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd9ca8",
   "metadata": {},
   "source": [
    "# Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ff76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_activity_plot(embedding_dist, activation_dist, r):\n",
    "    # standardize for plotting:\n",
    "    mask = np.ones((embedding_dist.shape[0],embedding_dist.shape[0])) \n",
    "    mask = (mask - np.diag(np.ones(embedding_dist.shape[0]))).astype(np.bool)\n",
    "\n",
    "    embedding_dist[mask] = (embedding_dist[mask] - np.mean(embedding_dist[mask])) / np.std(embedding_dist[mask])\n",
    "    activation_dist[mask] = (activation_dist[mask] - np.mean(activation_dist[mask])) / np.std(activation_dist[mask])\n",
    "    \n",
    "    # visualize matrices:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(9,3.25), \n",
    "                             gridspec_kw={'wspace':0.2})\n",
    "    plt.axes(axes[0])\n",
    "    sns.heatmap(embedding_dist, square=True,\n",
    "                center=0, vmax=3, cmap=\"icefire_r\")\n",
    "    plt.title('Embedding distances', size=18, y=1.05)\n",
    "    plt.ylim(embedding_dist.shape[0],0)\n",
    "\n",
    "    plt.axes(axes[1])\n",
    "    sns.heatmap(activation_dist, square=True,\n",
    "                center=0, vmax=3, cmap=\"icefire_r\")\n",
    "    plt.title('Activity distances', size=18, y=1.05)\n",
    "    plt.ylim(activation_dist.shape[0],0)\n",
    "    \n",
    "    plt.text(-0.4, 1.1, 'r= ' + str(np.round(r,3)), fontweight='semibold',\n",
    "             transform=axes[1].transAxes, size=12, fontstyle='italic')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch mean activations by participant as p x v\n",
    "p_activations = np.empty((len(dtfa.subjects()),dtfa.num_voxels))\n",
    "\n",
    "for i in range(p_embedding.shape[0]):\n",
    "    blocks_to_average = fetch_block_index(subjects=[int(p_embedding.participant[i])])\n",
    "    _, i_activations = create_brain_image(blocks_to_average, 'original')\n",
    "    p_activations[i,:] = i_activations[0,:]\n",
    "    \n",
    "p_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation and embedding dissimilarity (p x p matrices):\n",
    "embedding_dist = squareform(pdist(p_embedding[['x','y']]))\n",
    "activation_dist = squareform(pdist(p_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a75a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate the lower triangles\n",
    "l_idx = np.tril_indices(embedding_dist.shape[0], k=-1)\n",
    "corr, _ = spearmanr(embedding_dist[l_idx],activation_dist[l_idx])\n",
    "print('Spearmans correlation between participant embedding and activity distances: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bad88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_activity_plot(embedding_dist, activation_dist, corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864298ab",
   "metadata": {},
   "source": [
    "## Stimulus embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_embedding_sort = s_embedding.sort_values('situation').reset_index(drop=True)\n",
    "s_activations = np.empty((len(dtfa.tasks()),dtfa.num_voxels))\n",
    "\n",
    "for i in range(s_embedding_sort.shape[0]):\n",
    "    blocks_to_average = fetch_block_index(task=[s_embedding_sort.stimulus[i]])\n",
    "    _, i_activations = create_brain_image(blocks_to_average, 'original')\n",
    "    s_activations[i,:] = i_activations[0,:]\n",
    "    \n",
    "s_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation and embedding dissimilarity (p x p matrices):\n",
    "embedding_dist = squareform(pdist(s_embedding_sort[['x','y']]))\n",
    "activation_dist = squareform(pdist(s_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea53a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate the lower triangles\n",
    "l_idx = np.tril_indices(embedding_dist.shape[0], k=-1)\n",
    "corr, _ = spearmanr(embedding_dist[l_idx],activation_dist[l_idx])\n",
    "print('Spearmans correlation between stimulus embedding and activity distances: %.3f' % corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_activity_plot(embedding_dist, activation_dist, corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f63355",
   "metadata": {},
   "source": [
    "## Combination embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_activations = np.empty((c_embedding.shape[0],dtfa.num_voxels))\n",
    "\n",
    "for i in range(c_embedding.shape[0]):\n",
    "    block = fetch_block_index(subjects=[int(c_embedding.participant[i])],\n",
    "                              task=[c_embedding.stimulus[i]])\n",
    "    if len(block) > 1:\n",
    "        print('warning: more than one block found for this trial')\n",
    "    _, i_activations = create_brain_image(block, 'original')\n",
    "    c_activations[i,:] = i_activations[0,:]\n",
    "    \n",
    "c_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation and embedding dissimilarity (p x p matrices):\n",
    "embedding_dist = squareform(pdist(c_embedding[['x','y']]))\n",
    "activation_dist = squareform(pdist(c_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate the lower triangles\n",
    "l_idx = np.tril_indices(embedding_dist.shape[0], k=-1)\n",
    "corr, _ = spearmanr(embedding_dist[l_idx],activation_dist[l_idx])\n",
    "print('Spearmans correlation between combination embedding and activity distances: %.3f' % corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e27b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_activity_plot(embedding_dist, activation_dist, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421daa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embedding coordinate:\n",
    "        p_embedding, s_embedding, c_embedding = fetch_embeddings()\n",
    "\n",
    "        p_embedding.participant = p_embedding.participant.astype('int').astype('string')\n",
    "        p_embedding[['x','y']] = p_embedding[['x','y']].astype('float')\n",
    "\n",
    "        s_embedding[['x','y']] = s_embedding[['x','y']].astype('float')\n",
    "\n",
    "        c_embedding.participant = c_embedding.participant.astype('int').astype('string')\n",
    "        c_embedding[['x','y']] = c_embedding[['x','y']].astype('float')\n",
    "\n",
    "\n",
    "\n",
    "        # save embedding information in pickle\n",
    "        p_embedding.to_pickle(query_dir + 'p_embedding.pkl')\n",
    "        s_embedding.to_pickle(query_dir + 's_embedding.pkl')\n",
    "        c_embedding.to_pickle(query_dir + 'c_embedding.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac43eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "html_name = query_dir + f'NTFA_visualization_{linear_opts}.html'\n",
    "%store html_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
